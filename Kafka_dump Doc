h1. Kafka Dump Utility â€“ README

This page provides the full operational documentation for the Kafka Dump Utility, including design, configuration, execution, troubleshooting, and secure decryption procedures.

h2. 1. Overview

The Kafka Dump Utility securely extracts Kafka topic messages using a controlled, auditable, and encrypted workflow.
It was designed for:

SRE teams

Kafka Operations

Application Support

Compliance and Audit teams

The utility performs:

Metadata-rich Kafka dump

Compression (tar + gzip)

AES256 encryption via GPG

Upload to Artifactory

Zero residue cleanup

JSON-based Kafka cluster configuration

Disk usage protection

Structured INFO-level logging

Permanent audit-trail creation

h2. 2. Architecture Diagram

{code:mermaid}
flowchart TD

A[Frontend Self-Service Portal<br/>(INC, REQ, Topic, OTP)] --> B[kafka_dump.sh<br/>Secure Backend Script]

B --> C[(Kafka Cluster)]
B --> D[(GPG AES-256 Encryption)]
B --> E[(Audit Log<br/>/var/log/confluent/kafka_dump/audit.log)]
B --> F[(Temporary Dump Workspace<br/>/var/log/confluent/kafka_dump/INC/REQ/TOPIC)]

D --> G[(Encrypted Output<br/>REQ.tar.gz.gpg)]
G --> H[(Artifactory<br/>kafka-dump/INC/REQ/TOPIC)]
{code}

h2. 3. Features

|| Feature || Description ||
| Metadata-rich dump | Includes timestamp, offset, partition, key, headers, value |
| Strong encryption | GPG AES256 symmetric encryption with one-time password |
| Automatic cleanup | No plaintext left behind after script runs |
| Persistent audit log | JSON record for every run |
| Disk protection | Aborts when FS usage >= 85% |
| JSON-based configuration | No hardcoding of Kafka clusters |
| Retry logic | Kafka dump and Artifactory upload |
| Detailed INFO logs | Narrates each step of execution |

h2. 4. Directory Structure

Temporary working directory:
{code}
/var/log/confluent/kafka_dump/<INC>/<REQ>/<TOPIC>/
{code}

Persistent audit log (never deleted):
{code}
/var/log/confluent/kafka_dump/audit.log
{code}

h2. 5. JSON Configuration File

Location:
{code}
/etc/kafka_dump/cluster_map.json
{code}

Example:
{code:json}
{
"PHY-PROD-CL1": {
"PROD": {
"bootstrap": "phy-prod-kafka:9093",
"config": "/opt/kafka/conf/phy-prod-consumer.properties"
}
},
"VM-UAT-CL2": {
"UAT": {
"bootstrap": "vm-uat-kafka:9093",
"config": "/opt/kafka/conf/vm-uat-consumer.properties"
}
}
}
{code}

h2. 6. Required Environment Variables

|| Variable || Description ||
| ARTIFACTORY_BASE_URL | Base URL for uploads |
| ARTIFACTORY_USER | Username/token |
| ARTIFACTORY_PASSWORD | Password/token |
| KAFKA_BIN_DIR | (optional) Override Kafka binaries path |

h2. 7. Running the Script

Syntax:
{code}
kafka_dump.sh
--inc INC1234567
--req REQ-9876
--cluster PHY-PROD-CL1
--env PROD
--topic customer.transactions
--otp 'OneTimePassword'
--requestor rajiv
{code}

Success Output:
{code:json}
{
"status": "OK",
"artifactory_url": "https://.../REQ-9876.tar.gz.gpg
",
"message_count": 4823
}
{code}

Failure Output:
{code:json}
{
"status": "ERROR",
"message": "Disk usage 87% >= threshold 85%"
}
{code}

h2. 8. Artifactory Path Structure

{code}
kafka-dump/INC/<INC>/<REQ>/<TOPIC>/<REQ>.tar.gz.gpg
{code}

Example:
{code}
kafka-dump/INC/INC1234567/REQ-9876/customer.transactions/REQ-9876.tar.gz.gpg
{code}

h2. 9. How to Decrypt the Dump

h3. A. Linux / macOS

{code}
gpg --decrypt REQ-9876.tar.gz.gpg > dump.tar.gz
tar -xvf dump.tar.gz
{code}

You will be prompted for the OTP (One-Time Password).

h3. B. Windows (PowerShell)

{code}
gpg.exe --decrypt REQ-9876.tar.gz.gpg > dump.tar.gz
{code}

Extract with 7-Zip:
{code}
7z x dump.tar.gz
7z x dump.tar
{code}

h3. C. Verify SHA256 Checksum

{code}
sha256sum -c REQ-9876.tar.gz.gpg.sha256
{code}

Expected:
{code}
REQ-9876.tar.gz.gpg: OK
{code}

h2. 10. Troubleshooting

|| Issue || Possible Cause || Resolution ||
| Dump file empty | ACLs or connectivity | Validate consumer config & permissions |
| OTP fails | Extra whitespace | Re-copy OTP & retry |
| Disk usage error | FS >= 85% | Free space / extend volume |
| Artifactory failures | Bad credentials or network | Retry or rotate credentials |
| Decryption fails | Wrong passphrase or corrupted file | Run checksum verification |

h2. 11. Persistent Audit Log

Location:
{code}
/var/log/confluent/kafka_dump/audit.log
{code}

Audit entry example:
{code:json}
{
"ts": "2025-02-17T04:00:21Z",
"inc": "INC1234567",
"req": "REQ-9876",
"topic": "customer.transactions",
"user": "rajiv",
"status": "SUCCESS",
"reason": "",
"url": "https://.../REQ-9876.tar.gz.gpg
"
}
{code}
